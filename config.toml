[args]
strategy = "train" # train | test
data_path = "/app/test.xlsx" # xlsx、csv、json、parquet
train_column = "text"
max_new_tokens = 100

[Pretrained]
model_name = "Qwen/Qwen2.5-14B"
load_in_4bit = false
fast_inference = false
max_seq_length = 3000

[Envs]
CUDA_VISIBLE_DEVICES = "0"
HF_ENDPOINT = "https://hf-mirror.com"
UNSLOTH_RETURN_LOGITS = "1"

[SFTConfig]
per_device_train_batch_size = 2 # 参数值调高 训练的速度快 显存高
gradient_accumulation_steps = 1 # 如果显存低 那么将这个参数值调高 训练的速度将慢
num_train_epochs = 3
learning_rate = 1e-5
logging_steps = 100
save_total_limit = 3
output_dir = "./model" # 训练的时候 这个目录是保持训练后的模型地址。如果测试的时候，那么这个目录就是加载你的模型
packing = false

[Peft]
r = 16
target_modules = ["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]
lora_alpha = 16
lora_dropout = 0
bias = "none"
use_gradient_checkpointing = "unsloth"
use_rslora = false
